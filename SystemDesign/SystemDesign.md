# System Design Interview Prep

---

## 1Ô∏è‚É£ How to Approach a System Design Interview

### üìå Step-by-Step Method

1. **Clarify Requirements**
   - Functional: What does it do?
   - Non-functional: Scale? Latency? Uptime? Security?

2. **Estimate Scale**
   - Daily users, RPS, storage volume

3. **High-Level Components**
   - Define key layers: frontend, gateway, services, DB, storage, cache

4. **Drill Down Per Component**
   - Describe internal logic, APIs, storage format, scaling strategy

5. **Address Non-Functional Goals**
   - Availability, Scalability, Security, Monitoring

6. **Discuss Trade-offs**
   - Justify your tech choices (SQL vs NoSQL, REST vs events)

---

## 2Ô∏è‚É£ Requirements Template

### ‚úÖ Functional
- Upload and view files
- Search metadata
- Real-time preview
- Admin management

### ‚úÖ Non-Functional
- 99.9% uptime
- Scale to 1M users
- Upload size: up to 500MB
- < 300ms latency (P95)

---

## 3Ô∏è‚É£ Scenario: Design a Healthcare DICOM Imaging System

### üß† Functional Breakdown
- Upload large DICOM files (via Web UI or API)
- Store securely
- Retrieve via search (patient ID, modality, date)
- View using medical imaging viewer

---

## 4Ô∏è‚É£ High-Level Architecture

[Client] ‚Üí [API Gateway] ‚Üí [Auth Service] ‚Üí [DICOM Upload Service]
‚Üì
[Metadata DB] (PostgreSQL)
[Blob Store] (S3)
[Queue: Processing Jobs] ‚Üí [Analysis Service]
[Viewer Service] ‚Üê [CDN/Image Proxy]

---


---

## 5Ô∏è‚É£ Key Components (Detailed)

### üîπ API Gateway
- Routes incoming requests
- AuthN/AuthZ checks
- Handles rate limiting

### üîπ Auth Service
- JWT/Cognito/SAML
- Role-based access: Radiologist, Technician

### üîπ DICOM Upload Service
- Multipart upload support
- Validates file type, size, headers
- Writes to S3
- Pushes event to queue for async analysis

### üîπ Metadata Database
- PostgreSQL (structured queries)
- Stores: patient ID, study UID, tags
- Indexed for fast lookup

### üîπ Analysis Service (Optional)
- Event-driven via SQS or Kafka
- Runs AI/ML pipelines or anonymizes data
- Saves result metadata back to DB

### üîπ Viewer Service
- Serves pre-rendered thumbnails
- Requests routed via CloudFront or ALB
- Caches in Redis or CDN

---

## 6Ô∏è‚É£ Scaling & Availability

### ‚úÖ Uploads
- Use S3 multipart upload
- Pre-signed URLs for secure direct uploads

### ‚úÖ Compute
- Auto-scale containers on ECS
- Use health checks and circuit breakers

### ‚úÖ DB Layer
- Read replicas
- Sharded by facility/region if scale increases
- Backup + restore (point-in-time)

### ‚úÖ Cache Layer
- Redis for recent image metadata
- CDN for static DICOM previews

---

## 7Ô∏è‚É£ Security, Auth, Rate Limiting

- HTTPS everywhere
- JWT tokens (Cognito / IdentityServer)
- Role-based access per API route
- WAF (Web Application Firewall)
- IP whitelisting (for hospital partners)
- AWS Secrets Manager for credentials
- Rate limit: 10 RPS/user, burst up to 50

---

## 8Ô∏è‚É£ Observability

### ‚úÖ Logging
- Structured logs: Correlation ID, Trace ID
- Serilog + CloudWatch/Splunk

### ‚úÖ Tracing
- OpenTelemetry + X-Ray
- Trace file upload ‚Üí storage ‚Üí database updates

### ‚úÖ Metrics
- Requests/sec
- Queue depth
- Failed uploads
- Time to retrieve

---

## 9Ô∏è‚É£ CI/CD + Deployment

- Code pushed ‚Üí GitHub Actions
- Build Docker image ‚Üí push to ECR
- Deploy to ECS using blue/green (CodeDeploy)
- Rollback if health checks fail
- Infra as Code (CloudFormation or Terraform)

---

## üîü Trade-offs, Pitfalls & Interview Traps

### ‚ùå Anti-patterns to Avoid
| Mistake                          | Better Alternative                  |
|----------------------------------|--------------------------------------|
| Single DB for all services       | Per-service DB (bounded context)     |
| Sync service-to-service calls    | Use async + retries + backoff        |
| Storing files in DB              | Use S3, GCS, or Blob storage         |
| 1 big container                  | Split services into microservices    |

---

## ‚úÖ Sample Interview Q&A

### Q1: How would you design a system to support 1M DICOM uploads/day?

**Answer:**
- Use S3 for massive file durability
- Asynchronous ingestion using SQS
- Stateless upload APIs for horizontal scaling
- CDN for repeat image access
- Redis + DB sharding for metadata lookup

---

### Q2: How do you ensure upload security?

- HTTPS with signed URLs
- Content-type filtering
- Virus scanning (Lambda / S3 trigger)
- Token-based upload auth

---

### Q3: How would you design a public REST API for external hospital systems?

- Expose via API Gateway
- Enforce OAuth2 / JWT
- Throttle via usage plans
- Log every access (compliance)

---

## üß† Interview Tips

- Always mention **scale assumptions**
- Prioritize **availability & data integrity**
- Speak in **layers**: network ‚Üí compute ‚Üí data ‚Üí security
- Discuss **failure modes** and mitigation

---

## ‚úÖ Summary

You should now be able to:
- Design multi-tier systems from scratch
- Communicate design clearly with trade-offs
- Pick cloud-native tools with reasoning
- Think like an architect: secure, observable, resilient

